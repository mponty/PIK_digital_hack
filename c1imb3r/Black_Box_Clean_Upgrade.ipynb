{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import gc\n",
    "sys.path.append('/usr/local/lib/python3.6/site-packages')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_economy(dataset):\n",
    "    features = np.array(dataset.dtypes[dataset.dtypes=='float64'].index)\n",
    "    for f in features:\n",
    "        dataset[f] = dataset[f].astype('float32')\n",
    "    features = np.array(dataset.dtypes[dataset.dtypes=='int64'].index)\n",
    "    for f in features:\n",
    "        dataset[f] = dataset[f].astype('int32')\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def my_drop_levels(dataset, sep = '_', brief = ''):\n",
    "    if dataset.columns.nlevels>1:\n",
    "        new_columns = np.array([], dtype = 'str')\n",
    "        for col_i in range(dataset.shape[1]):\n",
    "            col_name = brief\n",
    "            for level in range(dataset.columns.nlevels):\n",
    "                tmp_col_name = dataset.columns.levels[level][dataset.columns.labels[level][col_i]]#.astype('str')\n",
    "                tmp_col_name = str(tmp_col_name) \n",
    "                if (level>0) & (tmp_col_name!=''):\n",
    "                    col_name = col_name+'_'\n",
    "                col_name = col_name+tmp_col_name\n",
    "            new_columns = np.append(new_columns,col_name)\n",
    "            #print(col_name)\n",
    "        for level in range(dataset.columns.nlevels-1):\n",
    "            dataset.columns.droplevel(0)\n",
    "        dataset.columns = new_columns      \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_full():\n",
    "    train = pd.read_csv('datasets/train.csv', encoding='cp1251')\n",
    "    test = pd.read_csv('datasets/test.csv', encoding='cp1251')\n",
    "    \n",
    "    train['is_train'] = 1\n",
    "    test['is_train'] = 0\n",
    "    \n",
    "    full = pd.concat([train,test])\n",
    "    \n",
    "    del train, test\n",
    "    gc.collect()\n",
    "    \n",
    "    full = full.sort_values('month_cnt')\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    full['bulk_id_int'] = le.fit_transform(full['bulk_id'])\n",
    "    full['date1'] = pd.to_datetime(full['date1'], format='%Y-%m-%d')\n",
    "    GLOBAL_MINDATE = full['date1'].min()\n",
    "    full['Date_int'] = ((full['date1'] - GLOBAL_MINDATE)/np.timedelta64(1, 'D')).astype('int32')\n",
    "\n",
    "    full['Автомойка'] = (full['Автомойка']=='да').astype('int')\n",
    "    full['Входные группы'] = (full['Входные группы']=='да').astype('int')\n",
    "    full['Двор без машин'] = (full['Двор без машин']=='да').astype('int')\n",
    "    full['Класс объекта'] = full['Класс объекта'].map({'эконом':1, 'комфорт':3, 'стандарт':2})\n",
    "    full['Кладовые'] = (full['Кладовые']=='да').astype('int')\n",
    "    full['Колясочные'] = (full['Колясочные']=='да').astype('int')\n",
    "    full['Огорожена территория'] = (full['Огорожена территория']=='да').astype('int')\n",
    "    full['Подземная парковка'] = (full['Подземная парковка']=='да').astype('int')\n",
    "    full['Система мусоротведения'] = le.fit_transform(full['Система мусоротведения'])\n",
    "    full['Спортивная площадка'] = (full['Спортивная площадка']=='да').astype('int')\n",
    "    \n",
    "    #введем уникальные id\n",
    "    full['bulk_spalen_id'] = full['bulk_id_int'].astype('str')+'_'+full['spalen'].astype('str')\n",
    "    full['bulk_spalen_id'] = le.fit_transform(full['bulk_spalen_id'])\n",
    "     \n",
    "    # подсчитаем псевдо start_square (без учета возвращенных)\n",
    "    full['calc_start_square'] = full.groupby(['bulk_spalen_id'])['start_square'].shift(1) - full.groupby(['bulk_spalen_id'])['value'].shift(1)\n",
    "    full['calc_last_value'] = full.groupby(['bulk_spalen_id'])['value'].shift(1)\n",
    "    \n",
    "    full['date2'] = full.date1+ pd.offsets.MonthEnd(1)\n",
    "    \n",
    "    full['price_by_square'] = full['price']/full['mean_sq']\n",
    "    \n",
    "    \n",
    "    full = full.reset_index(drop = True)\n",
    "    \n",
    "    return full\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_flat():\n",
    "    le = LabelEncoder()\n",
    "    flat = pd.read_csv('datasets/flat.csv', encoding='cp1251')\n",
    "    flat = flat.rename(columns = {'id_bulk':'bulk_id'})\n",
    "    flat['id_flatwork_int'] = np.array(flat.index).astype('int')\n",
    "    \n",
    "    dict_bulk_spalen = full.loc[:, ('bulk_id','bulk_id_int','spalen','bulk_spalen_id')] \\\n",
    "                       .drop_duplicates() \n",
    "    dict_flat = flat[['id_flatwork_int','id_flatwork','bulk_id','spalen']].copy()\n",
    "\n",
    "    dict_flat = dict_flat.merge(dict_bulk_spalen, how = 'left')\n",
    "    \n",
    "    \n",
    "    flat['Автомойка'] = (flat['Автомойка']=='да').astype('int')\n",
    "    flat['Входные группы'] = (flat['Входные группы']=='да').astype('int')\n",
    "    flat['Двор без машин'] = (flat['Двор без машин']=='да').astype('int')\n",
    "    flat['Класс объекта'] = flat['Класс объекта'].map({'эконом':1, 'комфорт':3, 'стандарт':2}).astype('int')\n",
    "    flat['Кладовые'] = (flat['Кладовые']=='да').astype('int')\n",
    "    flat['Колясочные'] = (flat['Колясочные']=='да').astype('int')\n",
    "    flat['Огорожена территория'] = (flat['Огорожена территория']=='да').astype('int')\n",
    "    flat['Подземная парковка'] = (flat['Подземная парковка']=='да').astype('int')\n",
    "    flat['Система мусоротведения'] = le.fit_transform(flat['Система мусоротведения'])\n",
    "    flat['Спортивная площадка'] = (flat['Спортивная площадка']=='да').astype('int')\n",
    "    flat['otdelka'] = le.fit_transform(flat['otdelka'].fillna('nan'))\n",
    "    flat['vid'] = flat['vid'].map({'эконом':1, 'средний':2, 'хороший':3}).fillna(0).astype('int')\n",
    "    flat['plan_size'] = flat['plan_size'].map({'S':1, 'M':2, 'L':3, '-1':0}).astype('int')\n",
    "    flat['plan0'] = le.fit_transform(flat['plan0'].fillna('nan'))\n",
    "\n",
    "    flat['date_settle'] = pd.to_datetime(flat['date_settle'], format='%Y-%m-%d')\n",
    "    flat['date_salestart'] = pd.to_datetime(flat['date_salestart'], format='%Y-%m-%d')\n",
    "    \n",
    "    flat['sale'] = (pd.to_datetime(flat['sale'], format = '%Y-%m-%d %H:%M:%S') +  np.timedelta64(1,'D') \n",
    "                   ).dt.date\n",
    "\n",
    "\n",
    "    flat.loc[~flat['date_settle'].isna(),'dt_settle_salestart'] = ((flat.loc[~flat['date_settle'].isna(),'date_settle'] - flat.loc[~flat['date_settle'].isna(),'date_salestart'])/np.timedelta64(1, 'D')).astype('int32')\n",
    "\n",
    "    #заполним медианным значением\n",
    "    dt_settle_salestart_median = int(flat.loc[~flat['date_settle'].isna(),'dt_settle_salestart'].median())\n",
    "    flat.loc[flat['date_settle'].isna(),'dt_settle_salestart'] = dt_settle_salestart_median  \n",
    "    \n",
    "    flat['dt_settle_salestart'] = flat['dt_settle_salestart'].astype('int32')\n",
    "    \n",
    "    flat.loc[flat['date_settle'].isna(),'date_settle'] = flat.loc[flat['date_settle'].isna(),'date_salestart'] + np.timedelta64(dt_settle_salestart_median, 'D')\n",
    "    \n",
    "    \n",
    "    flat = flat.merge(dict_flat[['id_flatwork_int','bulk_spalen_id','bulk_id_int']], how = 'left', on = 'id_flatwork_int')\n",
    "     \n",
    "    return flat, dict_bulk_spalen, dict_flat\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_status():\n",
    "    \n",
    "\n",
    "\n",
    "    status = pd.read_csv('datasets/status.csv', encoding='cp1251')\n",
    "    status = status.merge(dict_flat, how = 'inner')\n",
    "\n",
    "    #удалим статусы-однодневки\n",
    "    status = status[status['datefrom']!=status['dateto']]\n",
    "\n",
    "    dict_stat = status[['stat','stat_name']].drop_duplicates()\n",
    "    dict_stat['can_be_sold'] = (~dict_stat.stat_name.isin(['Реализован','Статус после покупки'])).astype('int16')\n",
    "    dict_stat['sold'] = (dict_stat.stat_name.isin(['Реализован','Статус после покупки'])).astype('int16')\n",
    "    dict_stat['realize'] = (dict_stat.stat_name.isin(['Реализован'])).astype('int16')\n",
    "    dict_stat['stat_new'] = dict_stat['stat_name'].map({'Не реализуется':0,\n",
    "                                                        'В реализации (не на сайте)':1,\n",
    "                                                        'В реализации':2,\n",
    "                                                        'Онлайн бронирование':3,\n",
    "                                                        'Зарезервирован под клиента':3,\n",
    "                                                        'Платное бронирование':4,\n",
    "                                                        'Реализован':5,\n",
    "                                                        'Статус после покупки':6\n",
    "                                                        }).astype('int16')\n",
    "\n",
    "    status = status.merge(dict_stat[['stat','stat_new']], how = 'inner')\n",
    "\n",
    "\n",
    "    status['datefrom'] = (pd.to_datetime(status['datefrom'], format = '%Y-%m-%d %H:%M:%S') + np.timedelta64(1,'D')).dt.date.astype('str')\n",
    "    status['dateto'] = (pd.to_datetime(status['dateto'], format = '%Y-%m-%d %H:%M:%S') + np.timedelta64(1,'D')).dt.date.astype('str')\n",
    "\n",
    "\n",
    "    status['datefrom_dt'] = pd.to_datetime(status['datefrom'], format='%Y-%m-%d')\n",
    "    status['dateto_dt'] = pd.to_datetime(status['dateto'], format='%Y-%m-%d')\n",
    "\n",
    "\n",
    "    status = status.sort_values(['datefrom','dateto'])\n",
    "    status['last_stat_new'] = status.groupby(['id_flatwork_int'])['stat_new'].shift(1)#.fillna('stat_new')\n",
    "    status.loc[status['last_stat_new'].isna(),'last_stat_new'] = -1\n",
    "\n",
    "\n",
    "\n",
    "    status['delay'] = (status['dateto_dt']-status['datefrom_dt'])/np.timedelta64(1,'D')\n",
    "\n",
    "\n",
    "    gc.collect() \n",
    "    \n",
    "    return status, dict_stat\n",
    "    \n",
    "def prepare_price():\n",
    "    \n",
    "    price = pd.read_csv('datasets/price.csv', encoding='utf-8')\n",
    "    price = price.merge(dict_flat, how = 'inner')\n",
    "\n",
    "    #удалим пустые цены и цены однодневки\n",
    "    price = price[(price.pricem2>1) & (price['datefrom']!=price['dateto'])].sort_values(['datefrom','dateto'])\n",
    "\n",
    "    price['datefrom'] = (pd.to_datetime(price['datefrom'], format = '%Y-%m-%d %H:%M:%S') + np.timedelta64(1,'D')).dt.date.astype('str')\n",
    "    price['dateto'] = (pd.to_datetime(price['dateto'], format = '%Y-%m-%d %H:%M:%S') + np.timedelta64(1,'D')).dt.date.astype('str')\n",
    "\n",
    "\n",
    "    price['last_pricem2'] = price.groupby(['id_flatwork_int'])['pricem2'].shift(1).fillna(0)\n",
    "    price['diff_pricem2'] = price['pricem2'] - price['last_pricem2']\n",
    "    price['was_decrease'] = (price['diff_pricem2'] < 0).astype('int32')\n",
    "\n",
    "\n",
    "\n",
    "    price['datefrom_dt'] = pd.to_datetime(price['datefrom'], format='%Y-%m-%d')\n",
    "    price['dateto_dt'] = pd.to_datetime(price['dateto'], format='%Y-%m-%d')\n",
    "\n",
    "    price = price.merge(flat.loc[:,('sale','id_flatwork_int')], how = 'left')\n",
    "    price['sale'] = pd.to_datetime(price['sale'], format='%Y-%m-%d')\n",
    "    price['is_saled_price'] = ((price['sale']>=price['datefrom_dt']) & (price['sale']<price['dateto_dt'])).astype('int')\n",
    "\n",
    "    price['delay'] = (price['dateto_dt']-price['datefrom_dt'])/np.timedelta64(1,'D')\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_flat_train(test_days_period):\n",
    "    \n",
    "\n",
    "    fixed_dates = np.sort(full.date1.dt.strftime('%Y-%m-%d').unique())\n",
    "    fixed_dates_last = np.sort(full.date2.dt.strftime('%Y-%m-%d').unique())\n",
    "\n",
    "\n",
    "    for i in range(len(fixed_dates)):\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "        fixed_date = fixed_dates[i] \n",
    "        fixed_date_last = fixed_dates_last[i]\n",
    "\n",
    "\n",
    "        #найдем квартиры, доступные к продаже на эту дату\n",
    "        status_on_date = status[(status.datefrom<=fixed_date) & (status.dateto>fixed_date)].copy()\n",
    "\n",
    "\n",
    "        #срок жизни статуса\n",
    "        status_on_date['datefrom'] = pd.to_datetime(status_on_date['datefrom'], format='%Y-%m-%d')\n",
    "        status_on_date['datenow'] = pd.to_datetime(fixed_date, format='%Y-%m-%d')\n",
    "        #status_on_date['dateto'] = pd.to_datetime(status_on_date['dateto'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        status_on_date['status_days'] = ((status_on_date['datenow'] - \n",
    "                                          status_on_date['datefrom'])/np.timedelta64(1, 'D')).astype('int32')\n",
    "\n",
    "        #подсчитаем все статусы, которые были у этой квартиры к указанной дате\n",
    "        statuses_to_date = status[(status.datefrom<=fixed_date)] \\\n",
    "                        .groupby(['id_flatwork_int','stat_new']) \\\n",
    "                        .size() \\\n",
    "                        .reset_index(name = 'cnt_stat_new')\n",
    "        statuses_to_date = statuses_to_date.pivot(index = 'id_flatwork_int', columns='stat_new').fillna(0)\n",
    "        statuses_to_date = my_drop_levels(statuses_to_date, sep = '_') \n",
    "        statuses_to_date = statuses_to_date.reset_index()\n",
    "\n",
    "        #удалим задвоения\n",
    "        tmp = status_on_date.groupby('id_flatwork_int').size().reset_index(name = 'cnt')\n",
    "        flats_to_delete =  tmp.loc[tmp['cnt']>1,'id_flatwork_int']\n",
    "        status_on_date = status_on_date[~status_on_date.id_flatwork_int.isin(flats_to_delete)] \n",
    "\n",
    "        #квартиры, которые могут быть проданы в этом периоде\n",
    "        stats_can_be_sold = dict_stat[dict_stat['can_be_sold']==1].stat\n",
    "        flats_can_be_sold = np.array(status_on_date[status_on_date.stat.isin(stats_can_be_sold)] \\\n",
    "                                     .id_flatwork_int)\n",
    "\n",
    "        #  \n",
    "        stats_sold = dict_stat[dict_stat['sold']==1].stat\n",
    "        flats_sold = status_on_date[status_on_date.stat.isin(stats_sold)].id_flatwork_int\n",
    "        \n",
    "        \n",
    "        flats_returned = np.array(flat[(flat.sale.astype('str')>fixed_date) & \n",
    "                              flat.id_flatwork_int.isin(flats_sold)].id_flatwork_int)\n",
    "        \n",
    "        flats_can_be_sold = np.append(flats_can_be_sold, flats_returned)\n",
    "        \n",
    "        #формируем простейшую поквартирную обучающую выборку\n",
    "        #Если реальная дата продажи > чем начало периода, то даже при статусе реализован, она может быть продана\n",
    "        tmp_flat_train = flat[(~flat.bulk_spalen_id.isna()) & \n",
    "                              (flat.date_salestart <= fixed_date_last) &\n",
    "                              (flat.id_flatwork_int.isin(flats_can_be_sold))].copy()\n",
    "\n",
    "        tmp_flat_train['date1']=fixed_date \n",
    "        tmp_flat_train['month_cnt']=i\n",
    "        tmp_flat_train['dt_to_settle'] = ((pd.to_datetime(tmp_flat_train['date1'], \n",
    "                                                          format='%Y-%m-%d')  - \n",
    "                                           tmp_flat_train['date_settle'])/np.timedelta64(1, 'D')).astype('int32')\n",
    "        tmp_flat_train['dt_to_salestart'] = ((pd.to_datetime(tmp_flat_train['date1'], format='%Y-%m-%d') - \n",
    "                                              tmp_flat_train['date_salestart'])/np.timedelta64(1, 'D')).astype('int32')\n",
    "\n",
    "        tmp_flat_train['dt_to_sale'] = ((pd.to_datetime(tmp_flat_train['sale'], \n",
    "                                                        format='%Y-%m-%d') - \n",
    "                                         pd.to_datetime(tmp_flat_train['date1'], \n",
    "                                                        format='%Y-%m-%d'))/np.timedelta64(1, 'D')).astype('int32')  \n",
    "\n",
    "        tmp_flat_train = tmp_flat_train.merge(status_on_date[['id_flatwork_int','stat_new',\n",
    "                                                              'last_stat_new','status_days']], \n",
    "                                              how = 'inner', \n",
    "                                              on = 'id_flatwork_int')\n",
    "        tmp_flat_train = tmp_flat_train.merge(statuses_to_date, how = 'left', on = 'id_flatwork_int')\n",
    "\n",
    "        #цена на дату\n",
    "        price_on_date = price[(price.datefrom<=fixed_date) & (price.dateto>fixed_date)].copy()\n",
    "        price_on_date['datefrom'] = pd.to_datetime(price_on_date['datefrom'], format='%Y-%m-%d')\n",
    "        price_on_date['datenow'] = pd.to_datetime(fixed_date, format='%Y-%m-%d')\n",
    "        #status_on_date['dateto'] = pd.to_datetime(status_on_date['dateto'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        price_on_date['price_days'] = ((price_on_date['datenow'] - \n",
    "                                        price_on_date['datefrom'])/np.timedelta64(1, 'D')).astype('int32')\n",
    "\n",
    "\n",
    "        tmp_flat_train = tmp_flat_train.merge(price_on_date[['id_flatwork_int','pricem2',\n",
    "                                                             'last_pricem2','diff_pricem2',\n",
    "                                                             'price_days','was_decrease']], \n",
    "                                              how = 'inner', \n",
    "                                              on = 'id_flatwork_int')\n",
    "\n",
    "\n",
    "        #исторические движения по цене\n",
    "        prices_to_date = price[(price.datefrom<=fixed_date) & (price.pricem2>1)] \\\n",
    "                        .groupby(['id_flatwork_int']) \\\n",
    "                        .agg({'pricem2':('min','max','mean','median','std'),\n",
    "                              'was_decrease':('sum','mean','std')})\n",
    "\n",
    "        prices_to_date = my_drop_levels(prices_to_date, sep = '_') \n",
    "        prices_to_date = prices_to_date.reset_index()\n",
    "        tmp_flat_train = tmp_flat_train.merge(prices_to_date, how = 'left', on = 'id_flatwork_int')\n",
    "\n",
    "\n",
    "        if i==0:\n",
    "            flat_train = tmp_flat_train.fillna(0)\n",
    "        else:\n",
    "            flat_train = flat_train.append(tmp_flat_train.fillna(0))\n",
    "\n",
    "       \n",
    "\n",
    "    flat_train = flat_train.fillna(0) \n",
    "\n",
    "\n",
    "    flat_train['realized_1'] = ((flat_train.dt_to_sale>=0) & \n",
    "                                (flat_train.dt_to_sale<test_days_period[0])).astype('int')\n",
    "    flat_train['realized_2'] = ((flat_train.dt_to_sale>=test_days_period[0]) & \n",
    "                                (flat_train.dt_to_sale<test_days_period[0]+test_days_period[1])).astype('int')           \n",
    "    flat_train['realized_3'] = ((flat_train.dt_to_sale>=test_days_period[0]+test_days_period[1]) & \n",
    "                                (flat_train.dt_to_sale<=test_days_period[0]+test_days_period[1]+test_days_period[2])).astype('int') \n",
    "\n",
    "    flat_train['value_1'] = flat_train['square']*flat_train['realized_1']\n",
    "    flat_train['value_2'] = flat_train['square']*flat_train['realized_2']\n",
    "    flat_train['value_3'] = flat_train['square']*flat_train['realized_3']\n",
    "    \n",
    "    \n",
    "    #может иметь психологический эффект\n",
    "    flat_train['price'] = flat_train['pricem2']*flat_train['square']\n",
    "\n",
    "    tmp = flat_train[(flat_train['pricem2']>1) & (flat_train['stat_new']>0) & (flat_train['stat_new']<5)] \\\n",
    "                    .groupby(['month_cnt','bulk_spalen_id']) \\\n",
    "                    .agg({'price':('min','max','std','count','median'),\n",
    "                          'pricem2':('min','max','std','median')})\n",
    "\n",
    "    tmp = my_drop_levels(tmp, sep = '_', brief = 'bulk_spalen_').reset_index()\n",
    "\n",
    "    flat_train = flat_train.merge(tmp, on = ['month_cnt','bulk_spalen_id'], how = 'left').fillna(0)\n",
    "\n",
    "    del tmp\n",
    "    gc.collect()\n",
    "\n",
    "    flat_train['diff_pricem2_median'] = flat_train['bulk_spalen_pricem2_median']-flat_train['pricem2']\n",
    "    flat_train['diff_price_median'] = flat_train['bulk_spalen_price_median']-flat_train['price']\n",
    "\n",
    "    flat_train['diff_pricem2_min'] = flat_train['pricem2'] - flat_train['bulk_spalen_pricem2_min']\n",
    "    flat_train['diff_price_min'] = flat_train['price'] - flat_train['bulk_spalen_price_min']\n",
    "\n",
    "    flat_train['diff_pricem2_max'] = flat_train['bulk_spalen_pricem2_max']-flat_train['pricem2']\n",
    "    flat_train['diff_price_max'] = flat_train['bulk_spalen_price_max']-flat_train['price']\n",
    "\n",
    "\n",
    "    tmp = flat_train[(flat_train['stat_new']>0) & (flat_train['stat_new']<5)] \\\n",
    "                    .groupby(['month_cnt','bulk_spalen_id']) \\\n",
    "                    .agg({'square':('min','max','std','count','median','mean')})\n",
    "\n",
    "    tmp = my_drop_levels(tmp, sep = '_', brief = 'bulk_spalen_').reset_index()\n",
    "\n",
    "    flat_train = flat_train.merge(tmp, on = ['month_cnt','bulk_spalen_id'], how = 'left').fillna(0)\n",
    "\n",
    "    del tmp\n",
    "    gc.collect()\n",
    "\n",
    "    flat_train['diff_square_median'] = flat_train['bulk_spalen_square_median']-flat_train['square']\n",
    "    flat_train['diff_square_mean'] = flat_train['bulk_spalen_square_mean']-flat_train['square']\n",
    "    flat_train['diff_square_min'] = flat_train['bulk_spalen_square_min']-flat_train['square']\n",
    "    flat_train['diff_square_max'] = flat_train['bulk_spalen_square_max']-flat_train['square']\n",
    "\n",
    "\n",
    "\n",
    "    tmp = flat_train.groupby(['month_cnt','bulk_spalen_id', 'stat_new']) \\\n",
    "                    .size() \\\n",
    "                    .reset_index(name = 'dolya_stat_new')\n",
    "\n",
    "    tmp1 = flat_train.groupby(['month_cnt','bulk_spalen_id']) \\\n",
    "                    .size() \\\n",
    "                    .reset_index(name = 'cnt_stat_new') \n",
    "\n",
    "\n",
    "    tmp1['unique_id'] = tmp1['month_cnt'].astype('str')+'_'+tmp1['bulk_spalen_id'].astype('str')\n",
    "\n",
    "    tmp = tmp.merge(tmp1) \n",
    "    tmp['dolya_stat_new']=tmp['dolya_stat_new']/tmp['cnt_stat_new']\n",
    "\n",
    "\n",
    "    tmp2 = tmp[['unique_id','stat_new','dolya_stat_new']].pivot(index = 'unique_id', columns='stat_new') \\\n",
    "                                                         .fillna(0) \n",
    "\n",
    "    tmp2 = my_drop_levels(tmp2, sep = '_', brief = 'bulk_spalen_').reset_index()\n",
    "    tmp2 = tmp2.merge(tmp1) \n",
    "    #tmp = my_drop_levels(tmp, sep = '_', brief = 'bulk_spalen_').reset_index()\n",
    "\n",
    "    flat_train = flat_train.merge(tmp2.drop('unique_id', axis = 1), on = ['month_cnt','bulk_spalen_id'], how = 'left').fillna(0) \n",
    "\n",
    "    del tmp, tmp1, tmp2\n",
    "    gc.collect()\n",
    "\n",
    "    flat_train['month'] = pd.to_datetime(flat_train.date1, format = '%Y-%m-%d').dt.month\n",
    "    \n",
    "    flat_train = mem_economy(flat_train)\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    tmp = flat_train.groupby(['month_cnt','bulk_spalen_id', 'stat_new']) \\\n",
    "                    .agg({'square':'sum'}) \\\n",
    "                    .reset_index() \\\n",
    "                    .rename(columns = {'square':'dolya_sqr_stat_new'})\n",
    "\n",
    "    tmp1 = flat_train.groupby(['month_cnt','bulk_spalen_id']) \\\n",
    "                    .agg({'square':'sum'}) \\\n",
    "                    .reset_index() \\\n",
    "                    .rename(columns = {'square':'sqr_stat_new'})\n",
    "\n",
    "\n",
    "    tmp1['unique_id'] = tmp1['month_cnt'].astype('str')+'_'+tmp1['bulk_spalen_id'].astype('str')\n",
    "\n",
    "    tmp = tmp.merge(tmp1) \n",
    "    tmp['dolya_sqr_stat_new']=tmp['dolya_sqr_stat_new']/tmp['sqr_stat_new']\n",
    "\n",
    "\n",
    "    tmp2 = tmp[['unique_id','stat_new','dolya_sqr_stat_new']].pivot(index = 'unique_id', columns='stat_new') \\\n",
    "                                                         .fillna(0) \n",
    "\n",
    "    tmp2 = my_drop_levels(tmp2, sep = '_', brief = 'bulk_spalen_').reset_index()\n",
    "    tmp2 = tmp2.merge(tmp1) \n",
    "    #tmp = my_drop_levels(tmp, sep = '_', brief = 'bulk_spalen_').reset_index()\n",
    "\n",
    "    flat_train = flat_train.merge(tmp2.drop('unique_id', axis = 1), on = ['month_cnt','bulk_spalen_id'], how = 'left').fillna(0) \n",
    "\n",
    "    del tmp, tmp1, tmp2\n",
    "    gc.collect()\n",
    "\n",
    "    return flat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.2 s, sys: 243 ms, total: 3.45 s\n",
      "Wall time: 3.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full = prepare_full()\n",
    "flat, dict_bulk_spalen, dict_flat = prepare_flat()\n",
    "\n",
    "full = mem_economy(full)\n",
    "gc.collect()\n",
    "flat = mem_economy(flat)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Добавим данные о максимальной площади, доступной для продажи\n",
    "max_sale_square = flat[flat['sale'].astype('str')>valid_date].groupby('bulk_spalen_id') \\\n",
    "                                                             .square.sum() \\\n",
    "                                                             .reset_index(name = 'max_square')\n",
    "\n",
    "full = full.merge(max_sale_square, on = 'bulk_spalen_id', how = 'left').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 s, sys: 429 ms, total: 18.4 s\n",
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "status, dict_stat = prepare_status()\n",
    "price             = prepare_price()\n",
    "\n",
    "#status = mem_economy(status)\n",
    "#price  = mem_economy(price)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формируем поквартирную обучающую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.8 s, sys: 2.97 s, total: 40.8 s\n",
      "Wall time: 40.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tmp_calendar = full.loc[full['is_train']==0,('date1','date2')].sort_values('date1').drop_duplicates()\n",
    "test_days_period =  np.array(((tmp_calendar.date2 - tmp_calendar.date1)/np.timedelta64(1,'D')+1).astype('int32')) \n",
    "\n",
    "print(f'test_days_period = {test_days_period:}')\n",
    "flat_train = prepare_flat_train(test_days_period)\n",
    "\n",
    "flat_train = mem_economy(flat_train)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train и test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_simple_cv(model, dataset, study_columns, random_state=442, importance_flag = False):\n",
    "    \n",
    "    train_agg = dataset[dataset.is_train==1].copy().reset_index(drop = True)\n",
    "    test_agg = dataset[dataset.is_train==0].copy().reset_index(drop = True)\n",
    "    \n",
    "    ind = 0\n",
    "    _mse = np.array([],dtype = 'float')\n",
    "    #заполним нулями предикт теста\n",
    "    y_test_pred = np.zeros(test_agg.shape[0],dtype = 'float')\n",
    "    \n",
    "    \n",
    "    #основная кросс-валидация\n",
    "    for train_index, valid_index in KFold(n_splits=5, random_state=random_state, shuffle = True).split(train_agg):   \n",
    "\n",
    "        tmp_train  = train_agg.loc[train_index,:]\n",
    "        tmp_valid  = train_agg.loc[valid_index,:]\n",
    "        tmp_test   = test_agg.copy()\n",
    "\n",
    "        #учиться будем только на study_columns не на всех переменных     \n",
    "        X_train = tmp_train.loc[:,study_columns]\n",
    "        X_valid = tmp_valid.loc[:,study_columns]\n",
    "        X_test  = tmp_test.loc[:,study_columns]\n",
    "\n",
    "        y_train = tmp_train['value']\n",
    "        y_valid = tmp_valid['value']\n",
    "        y_test = tmp_test['value'] \n",
    "        \n",
    "                \n",
    "        #обучим модель\n",
    "        model.fit(X_train,y_train)\n",
    " \n",
    "        y_valid_pred = model.predict(X_valid)\n",
    "        y_test_pred = y_test_pred+model.predict(X_test)\n",
    "        \n",
    "        \n",
    "        y_valid_pred[y_valid_pred<0] = 0\n",
    "        \n",
    "        if ind ==0:\n",
    "            stacking_df = pd.DataFrame(dict({'bulk_id_int':tmp_valid.bulk_id_int,'predict':y_valid_pred, 'fact':y_valid}))\n",
    "        else:\n",
    "            tmp_stacking_df = pd.DataFrame(dict({'bulk_id_int':tmp_valid.bulk_id_int,'predict':y_valid_pred, 'fact':y_valid}))\n",
    "            stacking_df = stacking_df.append(tmp_stacking_df).sort_values('bulk_id_int')\n",
    "        \n",
    "        \n",
    "        _mse = np.append(_mse,mean_squared_error(y_valid,y_valid_pred))\n",
    "\n",
    "        ind = ind + 1\n",
    "\n",
    "        #break\n",
    "    \n",
    "    \n",
    "    importance = pd.DataFrame(dict({'feature':'none', 'delta_mse':0}), index = ['none'])\n",
    "    \n",
    "    mse_now = mean_squared_error(y_valid,y_valid_pred)\n",
    "    NUMBER_SHUFFLE = 5\n",
    "    if importance_flag:\n",
    "        for feature in study_columns:\n",
    "\n",
    "            tmp_mse = 0\n",
    "            for i in range(NUMBER_SHUFFLE):\n",
    "                _X_valid = X_valid.copy()\n",
    "                a = np.asarray(X_valid[feature].copy())\n",
    "                np.random.shuffle(a)\n",
    "                _X_valid[feature] = a\n",
    "                y_valid_pred = model.predict(_X_valid)\n",
    "                tmp_mse = tmp_mse+mean_squared_error(y_valid, y_valid_pred)/NUMBER_SHUFFLE\n",
    "            tmp_importance = pd.DataFrame(dict({'feature':feature, 'delta_mse':(tmp_mse-mse_now)}), index = [feature])    \n",
    "            importance = importance.append(tmp_importance) \n",
    "    \n",
    "    \n",
    "    #усредняем по фолдам предсказание теста\n",
    "    y_test_pred = y_test_pred/ind\n",
    "    \n",
    "    y_test_pred[y_test_pred<0] = 0\n",
    "    \n",
    "    submission = pd.DataFrame(dict({'id':test_agg.id,'value':y_test,'predict':y_test_pred, 'bulk_spalen_id':test_agg.bulk_spalen_id}))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return submission, _mse, stacking_df, importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_algo = 260.5964 rmse_real = 260.2869\n"
     ]
    }
   ],
   "source": [
    "full['calc_last_value'] = full['calc_last_value'].fillna(0)\n",
    "full = full.reset_index(drop  = True)\n",
    "\n",
    "column_study = np.array(['До метро пешком(км)', 'price', 'mean_sq', 'price_by_square',\n",
    "       'mean_fl', 'Cтавка по ипотеке', 'Станций метро от кольца',\n",
    "       'Площадь двора', 'Date_int', 'До промки(км)', 'month',\n",
    "       'До большой дороги на машине(км)', 'spalen',\n",
    "       'Площадь зеленой зоны в радиусе 500 м', 'bulk_id_int',\n",
    "       'До удобной авторазвязки на машине(км)', 'До парка пешком(км)',\n",
    "       'Курс', 'До Кремля', 'Вклады свыше 3 лет','calc_last_value'])\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators = 150, random_state = 42)\n",
    "\n",
    "submission_lgb, mse, stacking_df, imp_df = my_simple_cv(lgb_model, \n",
    "                                                        full, \n",
    "                                                        column_study, \n",
    "                                                        random_state=442, \n",
    "                                                        importance_flag = True)\n",
    "\n",
    "#rmse на локальной валидации этой модели\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "submission_lgb = submission_lgb.sort_values('id')\n",
    "filename = f'results/afterparty/lgb_rmse_{(np.mean(rmse)):.4f} +- {(np.std(rmse)):.4f}.csv'\n",
    "submission_lgb.to_csv(filename, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_mse</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>calc_last_value</th>\n",
       "      <td>49290.487967</td>\n",
       "      <td>calc_last_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>До метро пешком(км)</th>\n",
       "      <td>34002.707916</td>\n",
       "      <td>До метро пешком(км)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>21326.906887</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_sq</th>\n",
       "      <td>13382.020355</td>\n",
       "      <td>mean_sq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>До Кремля</th>\n",
       "      <td>11102.768522</td>\n",
       "      <td>До Кремля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fl</th>\n",
       "      <td>9132.054308</td>\n",
       "      <td>mean_fl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cтавка по ипотеке</th>\n",
       "      <td>8642.821842</td>\n",
       "      <td>Cтавка по ипотеке</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>5281.245034</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>До большой дороги на машине(км)</th>\n",
       "      <td>5124.511238</td>\n",
       "      <td>До большой дороги на машине(км)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_by_square</th>\n",
       "      <td>4822.555239</td>\n",
       "      <td>price_by_square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>До парка пешком(км)</th>\n",
       "      <td>4786.377711</td>\n",
       "      <td>До парка пешком(км)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Площадь зеленой зоны в радиусе 500 м</th>\n",
       "      <td>4590.368181</td>\n",
       "      <td>Площадь зеленой зоны в радиусе 500 м</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Площадь двора</th>\n",
       "      <td>4243.500733</td>\n",
       "      <td>Площадь двора</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>До удобной авторазвязки на машине(км)</th>\n",
       "      <td>3137.576528</td>\n",
       "      <td>До удобной авторазвязки на машине(км)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spalen</th>\n",
       "      <td>2884.677641</td>\n",
       "      <td>spalen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Станций метро от кольца</th>\n",
       "      <td>2757.321446</td>\n",
       "      <td>Станций метро от кольца</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>До промки(км)</th>\n",
       "      <td>2731.018830</td>\n",
       "      <td>До промки(км)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_int</th>\n",
       "      <td>2379.355564</td>\n",
       "      <td>Date_int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bulk_id_int</th>\n",
       "      <td>2218.043688</td>\n",
       "      <td>bulk_id_int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Вклады свыше 3 лет</th>\n",
       "      <td>2080.251694</td>\n",
       "      <td>Вклады свыше 3 лет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Курс</th>\n",
       "      <td>808.758086</td>\n",
       "      <td>Курс</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          delta_mse  \\\n",
       "calc_last_value                        49290.487967   \n",
       "До метро пешком(км)                    34002.707916   \n",
       "price                                  21326.906887   \n",
       "mean_sq                                13382.020355   \n",
       "До Кремля                              11102.768522   \n",
       "mean_fl                                 9132.054308   \n",
       "Cтавка по ипотеке                       8642.821842   \n",
       "month                                   5281.245034   \n",
       "До большой дороги на машине(км)         5124.511238   \n",
       "price_by_square                         4822.555239   \n",
       "До парка пешком(км)                     4786.377711   \n",
       "Площадь зеленой зоны в радиусе 500 м    4590.368181   \n",
       "Площадь двора                           4243.500733   \n",
       "До удобной авторазвязки на машине(км)   3137.576528   \n",
       "spalen                                  2884.677641   \n",
       "Станций метро от кольца                 2757.321446   \n",
       "До промки(км)                           2731.018830   \n",
       "Date_int                                2379.355564   \n",
       "bulk_id_int                             2218.043688   \n",
       "Вклады свыше 3 лет                      2080.251694   \n",
       "Курс                                     808.758086   \n",
       "none                                       0.000000   \n",
       "\n",
       "                                                                     feature  \n",
       "calc_last_value                                              calc_last_value  \n",
       "До метро пешком(км)                                      До метро пешком(км)  \n",
       "price                                                                  price  \n",
       "mean_sq                                                              mean_sq  \n",
       "До Кремля                                                          До Кремля  \n",
       "mean_fl                                                              mean_fl  \n",
       "Cтавка по ипотеке                                          Cтавка по ипотеке  \n",
       "month                                                                  month  \n",
       "До большой дороги на машине(км)              До большой дороги на машине(км)  \n",
       "price_by_square                                              price_by_square  \n",
       "До парка пешком(км)                                      До парка пешком(км)  \n",
       "Площадь зеленой зоны в радиусе 500 м    Площадь зеленой зоны в радиусе 500 м  \n",
       "Площадь двора                                                  Площадь двора  \n",
       "До удобной авторазвязки на машине(км)  До удобной авторазвязки на машине(км)  \n",
       "spalen                                                                spalen  \n",
       "Станций метро от кольца                              Станций метро от кольца  \n",
       "До промки(км)                                                  До промки(км)  \n",
       "Date_int                                                            Date_int  \n",
       "bulk_id_int                                                      bulk_id_int  \n",
       "Вклады свыше 3 лет                                        Вклады свыше 3 лет  \n",
       "Курс                                                                    Курс  \n",
       "none                                                                    none  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_df.sort_values('delta_mse', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поквартирная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_submit(model, \n",
    "                        dataset, \n",
    "                        right_dataset, \n",
    "                        right_date, \n",
    "                        cv_dates,\n",
    "                        last_date,\n",
    "                        n_month,\n",
    "                        study_columns, \n",
    "                        value_column, \n",
    "                        group_columns, \n",
    "                        random_state=442, \n",
    "                        importance_flag = False):\n",
    "    \n",
    "    #весь обучающий датасет\n",
    "    train_agg = dataset.copy().reset_index(drop = True)\n",
    "    \n",
    "    ind = 0\n",
    "    _mse = np.array([],dtype = 'float')\n",
    "    _grp_mse = np.array([],dtype = 'float')\n",
    "    gc.collect()\n",
    "    print('==========================')\n",
    "    \n",
    "    #основная кросс-валидация\n",
    "    d = cv_dates[len(cv_dates)-1]\n",
    "     \n",
    "    #Расчитаем для submit-а\n",
    "\n",
    "    #обучающая сдвигается на 1 месяц вперед\n",
    "    dt = fixed_dates[d+1]\n",
    "    if d+1-n_month<0:\n",
    "        dt_start = fixed_dates[0]\n",
    "    else:\n",
    "        dt_start = fixed_dates[d+1-n_month]\n",
    "            \n",
    "    print('study dataset fot test: date = ',dt,' dt_start = ',dt_start)\n",
    "        \n",
    "    tmp_train  = train_agg.loc[(train_agg.date1<dt) & (train_agg.date1>=dt_start),:] \n",
    "    #а тестовая - на последнюю известную дату\n",
    "    tmp_test  = train_agg.loc[train_agg.date1==last_date,:]   \n",
    "    tmp_right = right_dataset.loc[right_dataset.date1==right_date,:].copy()\n",
    "        \n",
    "    #учиться будем только на study_columns не на всех переменных     \n",
    "    X_train = tmp_train.loc[:,study_columns]\n",
    "    X_test  = tmp_test.loc[:,study_columns]\n",
    "    \n",
    "    print('Максимальная дата обучающей ',tmp_train.date1.max())\n",
    "    print('Миниимальная дата тестовой ',tmp_test.date1.min())   \n",
    "    \n",
    "    y_train = tmp_train[value_column]\n",
    "        \n",
    "    del tmp_train\n",
    "    gc.collect()\n",
    "        \n",
    "    #обучим модель\n",
    "    model.fit(X_train,y_train)\n",
    "        \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred[y_test_pred<0] = 0\n",
    "        \n",
    "    R_test = X_test.copy()\n",
    "    R_test['predict'] = y_test_pred \n",
    "             \n",
    "    R_test = R_test.groupby(group_columns) \\\n",
    "                             .agg({'predict':'sum'}) \\\n",
    "                             .reset_index()\n",
    "    tmp_right = tmp_right.merge(R_test, on = group_columns, how = 'left')\n",
    "    submission = tmp_right[['id','bulk_spalen_id','predict']].rename(columns = {'predict':'value'}).fillna(0)\n",
    "    \n",
    "\n",
    "    return submission#, _mse, _grp_mse#, importance, model, full_df_for_calc_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cv(model, \n",
    "                        dataset, \n",
    "                        right_dataset, \n",
    "                        right_date, \n",
    "                        cv_dates,\n",
    "                        last_date,\n",
    "                        n_month,\n",
    "                        study_columns, \n",
    "                        value_column, \n",
    "                        group_columns, \n",
    "                        random_state=442, \n",
    "                        importance_flag = False):\n",
    "    \n",
    "    #весь обучающий датасет\n",
    "    train_agg = dataset.copy().reset_index(drop = True)\n",
    "    \n",
    "    ind = 0\n",
    "    _mse = np.array([],dtype = 'float')\n",
    "    _grp_mse = np.array([],dtype = 'float')\n",
    "    gc.collect()\n",
    "    print('==========================')\n",
    "    \n",
    "    #основная кросс-валидация\n",
    "    for d in cv_dates:\n",
    "        #получаем даты\n",
    "        dt = fixed_dates[d]\n",
    "        if d-n_month<0:\n",
    "            dt_start = fixed_dates[0]\n",
    "        else:\n",
    "            dt_start = fixed_dates[d-n_month]\n",
    "            \n",
    "        print('ind = ',ind, ' date = ',dt,' dt_start = ',dt_start)\n",
    "        \n",
    "        tmp_train  = train_agg.loc[(train_agg.date1<dt) & (train_agg.date1>=dt_start),:]   \n",
    "        tmp_valid  = train_agg.loc[train_agg.date1==dt,:]\n",
    "        tmp_right = right_dataset.loc[right_dataset.date1==dt,:].copy()\n",
    "        \n",
    "        #учиться будем только на study_columns не на всех переменных     \n",
    "        X_train = tmp_train.loc[:,study_columns]\n",
    "        X_valid = tmp_valid.loc[:,study_columns]\n",
    "        \n",
    "        y_train = tmp_train[value_column]\n",
    "        y_valid = tmp_valid[value_column]\n",
    "        \n",
    "        del tmp_train#, tmp_valid\n",
    "        gc.collect()\n",
    "        \n",
    "        #обучим модель\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        y_valid_pred = model.predict(X_valid)\n",
    "        y_valid_pred[y_valid_pred<0] = 0\n",
    "        \n",
    "        R_valid = tmp_valid[['bulk_spalen_id','id_flatwork_int']].copy() #X_valid.copy()\n",
    "        R_valid['predict'] = y_valid_pred\n",
    "        \n",
    "        print(f'X_valid.shape = {X_valid.shape:}')\n",
    "        _mse = np.append(_mse,mean_squared_error(y_valid,y_valid_pred))\n",
    "\n",
    "            \n",
    "        R_valid['value_flat'] = y_valid\n",
    "\n",
    "        R_valid = R_valid.groupby(group_columns) \\\n",
    "                             .agg({'predict':'sum','value_flat':'sum'}) \\\n",
    "                             .reset_index()\n",
    "        tmp_right = tmp_right.merge(R_valid, on = group_columns, how = 'left').fillna(0)\n",
    "            \n",
    "        if 1==0:\n",
    "            if ind == 0:\n",
    "                full_df_for_calc_cv = tmp_right[['value','predict']].copy()\n",
    "                full_df_for_calc_cv['ind'] = ind\n",
    "            else:\n",
    "                tmp_df_for_calc_cv = tmp_right[['value','predict']].copy()\n",
    "                tmp_df_for_calc_cv['ind'] = ind\n",
    "                full_df_for_calc_cv = full_df_for_calc_cv.append(tmp_df_for_calc_cv)\n",
    "\n",
    "            _grp_mse = np.append(_grp_mse,mean_squared_error(tmp_right['value'],tmp_right['predict']))\n",
    "\n",
    "        ind = ind + 1\n",
    "\n",
    "        #break\n",
    "        \n",
    "        \n",
    "    #посчитаем важность\n",
    "    importance = pd.DataFrame(dict({'feature':'none', 'delta_mse':0}), index = ['none'])\n",
    "    \n",
    "    mse_now = mean_squared_error(y_valid,y_valid_pred)\n",
    "    NUMBER_SHUFFLE = 5\n",
    "    if importance_flag:\n",
    "        for feature in study_columns:\n",
    "\n",
    "            tmp_mse = 0\n",
    "            for i in range(NUMBER_SHUFFLE):\n",
    "                _X_valid = X_valid.copy()\n",
    "                a = np.asarray(X_valid[feature].copy())\n",
    "                np.random.shuffle(a)\n",
    "                _X_valid[feature] = a\n",
    "                y_valid_pred = model.predict(_X_valid)\n",
    "                tmp_mse = tmp_mse+mean_squared_error(y_valid, y_valid_pred)/NUMBER_SHUFFLE\n",
    "            tmp_importance = pd.DataFrame(dict({'feature':feature, 'delta_mse':(tmp_mse-mse_now)}), index = [feature])    \n",
    "            importance = importance.append(tmp_importance)     \n",
    "    \n",
    "    #Расчитаем для submit-а\n",
    "    \n",
    "    #обучающая сдвигается на 1 месяц вперед\n",
    "    dt = fixed_dates[d+1]\n",
    "    if d+1-n_month<0:\n",
    "        dt_start = fixed_dates[0]\n",
    "    else:\n",
    "        dt_start = fixed_dates[d+1-n_month]\n",
    "            \n",
    "    print('study dataset fot test: date = ',dt,' dt_start = ',dt_start)\n",
    "        \n",
    "    tmp_train  = train_agg.loc[(train_agg.date1<dt) & (train_agg.date1>=dt_start),:] \n",
    "    #а тестовая - на последнюю известную дату\n",
    "    tmp_test  = train_agg.loc[train_agg.date1==last_date,:]   \n",
    "    tmp_right = right_dataset.loc[right_dataset.date1==right_date,:].copy()\n",
    "        \n",
    "    #учиться будем только на study_columns не на всех переменных     \n",
    "    X_train = tmp_train.loc[:,study_columns]\n",
    "    X_test  = tmp_test.loc[:,study_columns]\n",
    "        \n",
    "    y_train = tmp_train[value_column]\n",
    "        \n",
    "    del tmp_train\n",
    "    gc.collect()\n",
    "        \n",
    "    #обучим модель\n",
    "    model.fit(X_train,y_train)\n",
    "        \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred[y_test_pred<0] = 0\n",
    "        \n",
    "    R_test = tmp_test[['bulk_spalen_id','id_flatwork_int']].copy() #X_test.copy()\n",
    "    R_test['predict'] = y_test_pred \n",
    "             \n",
    "    R_test = R_test.groupby(group_columns) \\\n",
    "                             .agg({'predict':'sum'}) \\\n",
    "                             .reset_index()\n",
    "    tmp_right = tmp_right.merge(R_test, on = group_columns, how = 'left')\n",
    "    submission = tmp_right[['id','predict']].rename(columns = {'predict':'value'}).fillna(0)\n",
    "    \n",
    "\n",
    "    return submission, _mse, _grp_mse, importance, model#, full_df_for_calc_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "study dataset fot test: date =  2017-09-01  dt_start =  2016-12-01\n",
      "Максимальная дата обучающей  2017-08-01\n",
      "Миниимальная дата тестовой  2017-09-01\n",
      "==========================\n",
      "study dataset fot test: date =  2017-08-01  dt_start =  2016-11-01\n",
      "Максимальная дата обучающей  2017-07-01\n",
      "Миниимальная дата тестовой  2017-09-01\n",
      "==========================\n",
      "study dataset fot test: date =  2017-07-01  dt_start =  2016-10-01\n",
      "Максимальная дата обучающей  2017-06-01\n",
      "Миниимальная дата тестовой  2017-09-01\n",
      "CPU times: user 2min 3s, sys: 16.5 s, total: 2min 19s\n",
      "Wall time: 40.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fixed_dates = np.sort(full.date1.dt.strftime('%Y-%m-%d').unique())\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "#определим цену продажи\n",
    "column_filter = ['id_sec','id_gk','id_flatwork','date_settle', \n",
    "                 'date_salestart','sale','bulk_id',\n",
    "                 'date1','realized_1', 'realized_2', 'realized_3',\n",
    "                 'value_1','value_2', 'value_3','dt_to_sale']\n",
    "\n",
    "                \n",
    "column_study = np.setdiff1d(np.asarray(flat_train.columns), column_filter)\n",
    "\n",
    "\n",
    "last_date = full[full.is_train==0].date1.dt.date.astype('str').min()\n",
    "\n",
    "for i in range(1):\n",
    "    n_month = 15\n",
    "    lgb_model = lgb.LGBMRegressor(n_estimators = 200, random_state = 42+i, predict_leaf_index = True)\n",
    "    \n",
    "    submission_1 = my_submit(\n",
    "                            model = lgb_model, \n",
    "                            dataset = flat_train,\n",
    "                            right_dataset = full[['id','is_train','bulk_spalen_id','value','date1']],\n",
    "                            right_date = fixed_dates[-3], \n",
    "                            cv_dates = [len(fixed_dates)-4], \n",
    "                            last_date = last_date,\n",
    "                            n_month = n_month,\n",
    "                            study_columns = column_study, \n",
    "                            value_column = 'value_1', \n",
    "                            group_columns = 'bulk_spalen_id',\n",
    "                            random_state=442, \n",
    "                            importance_flag = True)\n",
    "\n",
    "    submission_2 = my_submit(\n",
    "                            model = lgb_model, \n",
    "                            dataset = flat_train,\n",
    "                            right_dataset = full[['id','is_train','bulk_spalen_id','value','date1']],\n",
    "                            right_date = fixed_dates[-2], \n",
    "                            cv_dates = [len(fixed_dates)-5],\n",
    "                            last_date = last_date,\n",
    "                            n_month = n_month,\n",
    "                            study_columns = column_study, \n",
    "                            value_column = 'value_2', \n",
    "                            group_columns = 'bulk_spalen_id',\n",
    "                            random_state=442, \n",
    "                            importance_flag = True)\n",
    "\n",
    "    submission_3 = my_submit(\n",
    "                            model = lgb_model, \n",
    "                            dataset = flat_train,\n",
    "                            right_dataset = full[['id','is_train','bulk_spalen_id','value','date1']],\n",
    "                            right_date = fixed_dates[-1],\n",
    "                            cv_dates = [len(fixed_dates)-6],\n",
    "                            last_date = last_date,\n",
    "                            n_month = n_month,\n",
    "                            study_columns = column_study, \n",
    "                            value_column = 'value_3', \n",
    "                            group_columns = 'bulk_spalen_id',\n",
    "                            random_state=442, \n",
    "                            importance_flag = True)\n",
    "\n",
    "\n",
    "    submission_flat = pd.concat([submission_1,submission_2,submission_3]).fillna(0).sort_values('id')\n",
    "    \n",
    "    if i==0:\n",
    "        v = submission_flat['value']\n",
    "    else: \n",
    "        v = v + submission_flat['value']\n",
    "        \n",
    "submission_flat['value'] = v/(i+1)  \n",
    "submission_flat = submission_flat.sort_values('id').reset_index(drop = True)\n",
    "\n",
    "filename = f'results/afterparty/x_{(i+1):}_nmonth_15.csv'\n",
    "submission_flat.to_csv(filename, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1126, 5)\n",
      "(1126, 5)\n"
     ]
    }
   ],
   "source": [
    "best_lgb = submission_lgb\n",
    "best_flat = submission_flat\n",
    "\n",
    "print(best_lgb.shape)\n",
    "print(best_flat.shape)\n",
    "\n",
    "best = best_flat.merge(best_lgb, on = ['id','bulk_spalen_id'], how = 'left')\n",
    "mic_c = 0.6\n",
    "\n",
    "best['predict'] = best['predict_x']\n",
    "best.loc[best['predict_x']==0, 'predict'] = best.loc[best['predict_x']==0, 'predict_y']\n",
    "best['predict'] = mic_c*best['predict']+(1-mic_c)*best['predict_y']\n",
    "     \n",
    "best['value'] = best['predict'] \n",
    "\n",
    "filename = f'results/afterparty/blend_auto_v1.csv'\n",
    "best[['id','value']].to_csv(filename, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Добавим информацию по максимальной площади, доступной для продажи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавим знания о квартирах\n",
    "max_sale_square = flat[flat['sale'].astype('str')>valid_date].groupby('bulk_spalen_id').agg({'square':'sum'}).reset_index()\n",
    "res_sale_square = best.groupby('bulk_spalen_id').agg({'predict':'sum'}).reset_index()\n",
    "\n",
    "res_sale_square = res_sale_square.merge(max_sale_square, on = 'bulk_spalen_id', how = 'left').fillna(0)\n",
    "res_sale_square['coeff'] = res_sale_square['square']/res_sale_square['predict']\n",
    "res_sale_square.loc[res_sale_square['coeff']>1, 'coeff'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_blend =  261.7682306960923\n"
     ]
    }
   ],
   "source": [
    "best = best.merge(res_sale_square[['bulk_spalen_id','coeff']], how = 'left', on = 'bulk_spalen_id')\n",
    "best['predict'] = best['predict']*best['coeff']\n",
    "\n",
    "best['value'] = best['predict'] \n",
    "\n",
    "filename = f'results/afterparty/blend_auto_v1_max.csv'\n",
    "best[['id','value']].to_csv(filename, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
