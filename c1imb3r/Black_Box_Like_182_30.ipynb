{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import gc\n",
    "sys.path.append('/usr/local/lib/python3.6/site-packages')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "#from hyperopt import hp, tpe\n",
    "#from hyperopt.fmin import fmin\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_full():\n",
    "    train = pd.read_csv('../datasets/train.csv', encoding='cp1251')\n",
    "    test = pd.read_csv('datasets/test.csv', encoding='cp1251')\n",
    "    \n",
    "    train['is_train'] = 1\n",
    "    test['is_train'] = 0\n",
    "    \n",
    "    full = pd.concat([train,test])\n",
    "    \n",
    "    del train, test\n",
    "    gc.collect()\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    full['bulk_id_int'] = le.fit_transform(full['bulk_id'])\n",
    "    full['date1'] = pd.to_datetime(full['date1'], format='%Y-%m-%d')\n",
    "    GLOBAL_MINDATE = full['date1'].min()\n",
    "    full['Date_int'] = ((full['date1'] - GLOBAL_MINDATE)/np.timedelta64(1, 'D')).astype('int32')\n",
    "\n",
    "    full['Автомойка'] = (full['Автомойка']=='да').astype('int')\n",
    "    full['Входные группы'] = (full['Входные группы']=='да').astype('int')\n",
    "    full['Двор без машин'] = (full['Двор без машин']=='да').astype('int')\n",
    "    full['Класс объекта'] = full['Класс объекта'].map({'эконом':1, 'комфорт':3, 'стандарт':2})\n",
    "    full['Кладовые'] = (full['Кладовые']=='да').astype('int')\n",
    "    full['Колясочные'] = (full['Колясочные']=='да').astype('int')\n",
    "    full['Огорожена территория'] = (full['Огорожена территория']=='да').astype('int')\n",
    "    full['Подземная парковка'] = (full['Подземная парковка']=='да').astype('int')\n",
    "    full['Система мусоротведения'] = le.fit_transform(full['Система мусоротведения'])\n",
    "    full['Спортивная площадка'] = (full['Спортивная площадка']=='да').astype('int')\n",
    "    \n",
    "    #введем уникальные id\n",
    "    full['bulk_spalen_id'] = full['bulk_id_int'].astype('str')+'_'+full['spalen'].astype('str')\n",
    "    full['bulk_spalen_id'] = le.fit_transform(full['bulk_spalen_id'])\n",
    "    \n",
    "    full = full.sort_values('month_cnt')\n",
    "    \n",
    "    # подсчитаем псевдо start_square (без учета возвращенных)\n",
    "    full['calc_start_square'] = full.groupby(['bulk_spalen_id'])['start_square'].shift(1) - full.groupby(['bulk_spalen_id'])['value'].shift(1)\n",
    "    full['calc_last_value'] = full.groupby(['bulk_spalen_id'])['value'].shift(1)\n",
    "    \n",
    "    full['date2'] = full.date1+ pd.offsets.MonthEnd(1)\n",
    "    \n",
    "    full['price_by_square'] = full['price']/full['mean_sq']\n",
    "    \n",
    "    return full\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_flat():\n",
    "    le = LabelEncoder()\n",
    "    flat = pd.read_csv('datasets/flat.csv', encoding='cp1251')\n",
    "    flat = flat.rename(columns = {'id_bulk':'bulk_id'})\n",
    "    flat['id_flatwork_int'] = np.array(flat.index).astype('int')\n",
    "    \n",
    "    dict_bulk_spalen = full.loc[:, ('bulk_id','spalen','bulk_spalen_id')] \\\n",
    "                       .drop_duplicates() \n",
    "    dict_flat = flat[['id_flatwork_int','id_flatwork','bulk_id','spalen']].copy()\n",
    "\n",
    "    dict_flat = dict_flat.merge(dict_bulk_spalen, how = 'left')\n",
    "    \n",
    "    \n",
    "    flat['Автомойка'] = (flat['Автомойка']=='да').astype('int')\n",
    "    flat['Входные группы'] = (flat['Входные группы']=='да').astype('int')\n",
    "    flat['Двор без машин'] = (flat['Двор без машин']=='да').astype('int')\n",
    "    flat['Класс объекта'] = flat['Класс объекта'].map({'эконом':1, 'комфорт':3, 'стандарт':2})\n",
    "    flat['Кладовые'] = (flat['Кладовые']=='да').astype('int')\n",
    "    flat['Колясочные'] = (flat['Колясочные']=='да').astype('int')\n",
    "    flat['Огорожена территория'] = (flat['Огорожена территория']=='да').astype('int')\n",
    "    flat['Подземная парковка'] = (flat['Подземная парковка']=='да').astype('int')\n",
    "    flat['Система мусоротведения'] = le.fit_transform(flat['Система мусоротведения'])\n",
    "    flat['Спортивная площадка'] = (flat['Спортивная площадка']=='да').astype('int')\n",
    "    flat['otdelka'] = le.fit_transform(flat['otdelka'].fillna('nan'))\n",
    "    flat['vid'] = flat['vid'].map({'эконом':1, 'средний':2, 'хороший':3}).fillna(0)\n",
    "    flat['plan_size'] = flat['plan_size'].map({'S':1, 'M':2, 'L':3, '-1':0})\n",
    "    flat['plan0'] = le.fit_transform(flat['plan0'].fillna('nan'))\n",
    "\n",
    "    flat['date_settle'] = pd.to_datetime(flat['date_settle'], format='%Y-%m-%d')\n",
    "    flat['date_salestart'] = pd.to_datetime(flat['date_salestart'], format='%Y-%m-%d')\n",
    "\n",
    "    flat.loc[~flat['date_settle'].isna(),'dt_settle_salestart'] = ((flat.loc[~flat['date_settle'].isna(),'date_settle'] - flat.loc[~flat['date_settle'].isna(),'date_salestart'])/np.timedelta64(1, 'D')).astype('int32')\n",
    "\n",
    "    #заполним медианным значением\n",
    "    dt_settle_salestart_median = int(flat.loc[~flat['date_settle'].isna(),'dt_settle_salestart'].median())\n",
    "    flat.loc[flat['date_settle'].isna(),'dt_settle_salestart'] = dt_settle_salestart_median  \n",
    "    \n",
    "    flat['dt_settle_salestart'] = flat['dt_settle_salestart'].astype('int32')\n",
    "    \n",
    "    flat.loc[flat['date_settle'].isna(),'date_settle'] = flat.loc[flat['date_settle'].isna(),'date_salestart'] + np.timedelta64(dt_settle_salestart_median, 'D')\n",
    "    \n",
    "    \n",
    "    flat = flat.merge(dict_flat[['id_flatwork_int','bulk_spalen_id']], how = 'left', on = 'id_flatwork_int')\n",
    "     \n",
    "    return flat, dict_bulk_spalen, dict_flat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = prepare_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat, dict_bulk_spalen, dict_flat = prepare_flat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = pd.read_csv('datasets/price.csv', encoding='utf-8')\n",
    "status = pd.read_csv('datasets/status.csv', encoding='cp1251')\n",
    "\n",
    "price = price.merge(dict_flat, how = 'inner')\n",
    "status = status.merge(dict_flat, how = 'inner')\n",
    "\n",
    "\n",
    "dict_stat = status[['stat','stat_name']].drop_duplicates()\n",
    "dict_stat['can_be_sold'] = (~dict_stat.stat_name.isin(['Реализован','Статус после покупки'])).astype('int')\n",
    "dict_stat['sold'] = (dict_stat.stat_name.isin(['Реализован','Статус после покупки'])).astype('int')\n",
    "dict_stat['realize'] = (dict_stat.stat_name.isin(['Реализован'])).astype('int')\n",
    "dict_stat['stat_new'] = dict_stat['stat_name'].map({'Не реализуется':0,\n",
    "                                                    'В реализации (не на сайте)':1,\n",
    "                                                    'В реализации':2,\n",
    "                                                    'Онлайн бронирование':3,\n",
    "                                                    'Зарезервирован под клиента':3,\n",
    "                                                    'Платное бронирование':4,\n",
    "                                                    'Реализован':5,\n",
    "                                                    'Статус после покупки':6\n",
    "                                                    })\n",
    "\n",
    "status = status.merge(dict_stat[['stat','stat_new']], how = 'inner')\n",
    "\n",
    "status = status.sort_values(['datefrom','dateto'])\n",
    "status['last_stat_new'] = status.groupby(['id_flatwork_int'])['stat_new'].shift(1)#.fillna('stat_new')\n",
    "status.loc[status['last_stat_new'].isna(),'last_stat_new'] = -1\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_drop_levels(dataset, sep = '_', brief = ''):\n",
    "    if dataset.columns.nlevels>1:\n",
    "        new_columns = np.array([], dtype = 'str')\n",
    "        for col_i in range(dataset.shape[1]):\n",
    "            col_name = brief\n",
    "            for level in range(dataset.columns.nlevels):\n",
    "                tmp_col_name = dataset.columns.levels[level][dataset.columns.labels[level][col_i]]#.astype('str')\n",
    "                tmp_col_name = str(tmp_col_name) \n",
    "                if (level>0) & (tmp_col_name!=''):\n",
    "                    col_name = col_name+'_'\n",
    "                col_name = col_name+tmp_col_name\n",
    "            new_columns = np.append(new_columns,col_name)\n",
    "            #print(col_name)\n",
    "        for level in range(dataset.columns.nlevels-1):\n",
    "            dataset.columns.droplevel(0)\n",
    "        dataset.columns = new_columns      \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формируем поквартирную обучающую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.8 s, sys: 3.11 s, total: 37.9 s\n",
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fixed_days = np.sort(full.date1.dt.strftime('%Y-%m-%d').unique())\n",
    "fixed_dates = np.sort(full.date1.dt.strftime('%Y-%m-%d').unique() + ' 21:00:00')\n",
    "fixed_dates_last = np.sort(full.date2.dt.strftime('%Y-%m-%d').unique() + ' 21:00:00')\n",
    "\n",
    "\n",
    "for i in range(len(fixed_days)):\n",
    "    gc.collect()\n",
    "    \n",
    "    fixed_day = fixed_days[i]\n",
    "    fixed_date = fixed_dates[i] \n",
    "    fixed_date_last = fixed_dates_last[i]\n",
    "\n",
    "\n",
    "    #найдем квартиры, доступные к продаже на эту дату\n",
    "    status_on_date = status[(status.datefrom<=fixed_date) & (status.dateto>fixed_date)].copy()\n",
    "    \n",
    "\n",
    "    #срок жизни статуса\n",
    "    status_on_date['datefrom'] = pd.to_datetime(status_on_date['datefrom'], format='%Y-%m-%d %H:%M:%S')\n",
    "    status_on_date['datenow'] = pd.to_datetime(fixed_date, format='%Y-%m-%d %H:%M:%S')\n",
    "    #status_on_date['dateto'] = pd.to_datetime(status_on_date['dateto'], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    status_on_date['status_days'] = ((status_on_date['datenow'] - status_on_date['datefrom'])/np.timedelta64(1, 'D')).astype('int32')\n",
    "    \n",
    "    #подсчитаем все статусы, которые были у этой квартиры к указанной дате\n",
    "    statuses_to_date = status[(status.datefrom<=fixed_date)] \\\n",
    "                    .groupby(['id_flatwork_int','stat_new']) \\\n",
    "                    .size() \\\n",
    "                    .reset_index(name = 'cnt_stat_new')\n",
    "    statuses_to_date = statuses_to_date.pivot(index = 'id_flatwork_int', columns='stat_new').fillna(0)\n",
    "    statuses_to_date = my_drop_levels(statuses_to_date, sep = '_') \n",
    "    statuses_to_date = statuses_to_date.reset_index()\n",
    "    \n",
    "    #удалим задвоения\n",
    "    tmp = status_on_date.groupby('id_flatwork_int').size().reset_index(name = 'cnt')\n",
    "    flats_to_delete =  tmp.loc[tmp['cnt']>1,'id_flatwork_int']\n",
    "    status_on_date = status_on_date[~status_on_date.id_flatwork_int.isin(flats_to_delete)] \n",
    "    \n",
    "    #квартиры, которые могут быть проданы в этом периоде\n",
    "    stats_can_be_sold = dict_stat[dict_stat['can_be_sold']==1].stat\n",
    "    flats_can_be_sold = status_on_date[status_on_date.stat.isin(stats_can_be_sold)].id_flatwork_int\n",
    "    \n",
    "    #формируем простейшую поквартирную обучающую выборку\n",
    "    tmp_flat_train = flat[(~flat.bulk_spalen_id.isna()) & \n",
    "                          (flat.id_flatwork_int.isin(flats_can_be_sold)) #| flat.id_flatwork_int.isin(flats_sold_by_period)\n",
    "                         ].copy()\n",
    "    \n",
    "    #за ближайший месяц\n",
    "    # таргет - поле sale за период\n",
    "    flats_sold_by_period = flat[(flat['sale'] >= fixed_date) & (flat['sale'] <= fixed_date_last)] \\\n",
    "                                    .id_flatwork_int \\\n",
    "                                    .unique()                  \n",
    "    tmp_flat_train['realized_1'] = (tmp_flat_train.id_flatwork_int.isin(flats_sold_by_period)).astype('int')\n",
    "    tmp_flat_train['value_1'] = tmp_flat_train['square']*tmp_flat_train['realized_1']\n",
    "    \n",
    "    if (i+1)<len(fixed_days):\n",
    "        # таргет - наличие статуса реализован за период\n",
    "        flats_sold_by_period = flat[(flat['sale'] >= fixed_dates[i+1]) & (flat['sale'] <= fixed_dates_last[i+1])] \\\n",
    "                                        .id_flatwork_int \\\n",
    "                                        .unique()                  \n",
    "        tmp_flat_train['realized_2'] = (tmp_flat_train.id_flatwork_int.isin(flats_sold_by_period)).astype('int')\n",
    "        tmp_flat_train['value_2'] = tmp_flat_train['square']*tmp_flat_train['realized_2']\n",
    "    \n",
    "    if (i+2)<len(fixed_days):\n",
    "        # таргет - наличие статуса реализован за период\n",
    "        flats_sold_by_period = flat[(flat['sale'] >= fixed_dates[i+2]) & (flat['sale'] <= fixed_dates_last[i+2])] \\\n",
    "                                        .id_flatwork_int \\\n",
    "                                        .unique()                  \n",
    "        tmp_flat_train['realized_3'] = (tmp_flat_train.id_flatwork_int.isin(flats_sold_by_period)).astype('int')\n",
    "        tmp_flat_train['value_3'] = tmp_flat_train['square']*tmp_flat_train['realized_3']\n",
    "    \n",
    "\n",
    "    tmp_flat_train = tmp_flat_train.merge(status_on_date[['id_flatwork_int','stat_new','last_stat_new','status_days']], how = 'inner', on = 'id_flatwork_int')\n",
    "    tmp_flat_train = tmp_flat_train.merge(statuses_to_date, how = 'left', on = 'id_flatwork_int')\n",
    "\n",
    "    \n",
    "    tmp_flat_train['date1']=fixed_day \n",
    "    tmp_flat_train['month_cnt']=i\n",
    "    tmp_flat_train['dt_to_settle'] = ((pd.to_datetime(tmp_flat_train['date1'], format='%Y-%m-%d')  - tmp_flat_train['date_settle'])/np.timedelta64(1, 'D')).astype('int32')\n",
    "    tmp_flat_train['dt_to_salestart'] = ((pd.to_datetime(tmp_flat_train['date1'], format='%Y-%m-%d') - tmp_flat_train['date_salestart'])/np.timedelta64(1, 'D')).astype('int32')\n",
    "   \n",
    "    #тут стоит поиграться со статусами, историей, ценой\n",
    "    price_on_date = price[(price.datefrom<=fixed_date) & (price.dateto>fixed_date)]\n",
    "    tmp_flat_train = tmp_flat_train.merge(price_on_date[['id_flatwork_int','pricem2']], how = 'inner', on = 'id_flatwork_int')\n",
    "    \n",
    "    #начнем со статусов\n",
    "    \n",
    "    \n",
    "    if i==0:\n",
    "        flat_train = tmp_flat_train.fillna(0)\n",
    "    else:\n",
    "        flat_train = flat_train.append(tmp_flat_train.fillna(0))\n",
    "    \n",
    "    #if i==19:\n",
    "    #    break\n",
    "    #break\n",
    "    \n",
    "flat_train = flat_train.fillna(0)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_economy(dataset):\n",
    "    features = np.array(dataset.dtypes[dataset.dtypes=='float64'].index)\n",
    "    for f in features:\n",
    "        dataset[f] = dataset[f].astype('float32')\n",
    "    features = np.array(dataset.dtypes[dataset.dtypes=='int64'].index)\n",
    "    for f in features:\n",
    "        dataset[f] = dataset[f].astype('int32')\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = mem_economy(full)\n",
    "gc.collect()\n",
    "flat = mem_economy(flat)\n",
    "gc.collect()\n",
    "flat_train = mem_economy(flat_train)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_submit(model, \n",
    "                        dataset, \n",
    "                        right_dataset, \n",
    "                        right_date, \n",
    "                        cv_dates,\n",
    "                        last_date,\n",
    "                        n_month,\n",
    "                        study_columns, \n",
    "                        value_column, \n",
    "                        group_columns, \n",
    "                        random_state=442, \n",
    "                        importance_flag = False):\n",
    "    \n",
    "    #весь обучающий датасет\n",
    "    train_agg = dataset.copy().reset_index(drop = True)\n",
    "    \n",
    "    ind = 0\n",
    "    _mse = np.array([],dtype = 'float')\n",
    "    _grp_mse = np.array([],dtype = 'float')\n",
    "    gc.collect()\n",
    "    print('==========================')\n",
    "    \n",
    "    #основная кросс-валидация\n",
    "    d = cv_dates[len(cv_dates)-1]\n",
    "     \n",
    "    #Расчитаем для submit-а\n",
    "\n",
    "    #обучающая сдвигается на 1 месяц вперед\n",
    "    dt = fixed_days[d+1]\n",
    "    if d+1-n_month<0:\n",
    "        dt_start = fixed_days[0]\n",
    "    else:\n",
    "        dt_start = fixed_days[d+1-n_month]\n",
    "            \n",
    "    print('study dataset fot test: date = ',dt,' dt_start = ',dt_start)\n",
    "        \n",
    "    tmp_train  = train_agg.loc[(train_agg.date1<dt) & (train_agg.date1>=dt_start),:] \n",
    "    #а тестовая - на последнюю известную дату\n",
    "    tmp_test  = train_agg.loc[train_agg.date1==last_date,:]   \n",
    "    tmp_right = right_dataset.loc[right_dataset.date1==right_date,:].copy()\n",
    "        \n",
    "    #учиться будем только на study_columns не на всех переменных     \n",
    "    X_train = tmp_train.loc[:,study_columns]\n",
    "    X_test  = tmp_test.loc[:,study_columns]\n",
    "        \n",
    "    y_train = tmp_train[value_column]\n",
    "        \n",
    "    del tmp_train\n",
    "    gc.collect()\n",
    "        \n",
    "    #обучим модель\n",
    "    model.fit(X_train,y_train)\n",
    "        \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred[y_test_pred<0] = 0\n",
    "        \n",
    "    R_test = X_test.copy()\n",
    "    R_test['predict'] = y_test_pred \n",
    "             \n",
    "    R_test = R_test.groupby(group_columns) \\\n",
    "                             .agg({'predict':'sum'}) \\\n",
    "                             .reset_index()\n",
    "    tmp_right = tmp_right.merge(R_test, on = group_columns, how = 'left')\n",
    "    submission = tmp_right[['id','predict']].rename(columns = {'predict':'value'}).fillna(0)\n",
    "    \n",
    "\n",
    "    return submission#, _mse, _grp_mse#, importance, model, full_df_for_calc_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "study dataset fot test: date =  2018-02-01  dt_start =  2016-11-01\n",
      "==========================\n",
      "study dataset fot test: date =  2018-01-01  dt_start =  2016-10-01\n",
      "==========================\n",
      "study dataset fot test: date =  2017-12-01  dt_start =  2016-09-01\n",
      "==========================\n",
      "study dataset fot test: date =  2018-02-01  dt_start =  2016-11-01\n",
      "==========================\n",
      "study dataset fot test: date =  2018-01-01  dt_start =  2016-10-01\n",
      "==========================\n",
      "study dataset fot test: date =  2017-12-01  dt_start =  2016-09-01\n",
      "==========================\n",
      "study dataset fot test: date =  2018-02-01  dt_start =  2016-11-01\n",
      "==========================\n",
      "study dataset fot test: date =  2018-01-01  dt_start =  2016-10-01\n",
      "==========================\n",
      "study dataset fot test: date =  2017-12-01  dt_start =  2016-09-01\n",
      "==========================\n",
      "study dataset fot test: date =  2018-02-01  dt_start =  2016-11-01\n",
      "==========================\n",
      "study dataset fot test: date =  2018-01-01  dt_start =  2016-10-01\n",
      "==========================\n",
      "study dataset fot test: date =  2017-12-01  dt_start =  2016-09-01\n",
      "==========================\n",
      "study dataset fot test: date =  2018-02-01  dt_start =  2016-11-01\n",
      "==========================\n",
      "study dataset fot test: date =  2018-01-01  dt_start =  2016-10-01\n",
      "==========================\n",
      "study dataset fot test: date =  2017-12-01  dt_start =  2016-09-01\n",
      "CPU times: user 10min 41s, sys: 1min 20s, total: 12min 1s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gc.collect()\n",
    "#определим цену продажи\n",
    "column_filter = ['id_sec','id_gk','id_flatwork','date_settle', \n",
    "                 'date_salestart','sale','bulk_id',\n",
    "                 'date1','realized_1', 'realized_2', 'realized_3',\n",
    "                 'value_1','value_2', 'value_3']\n",
    "\n",
    "                \n",
    "column_study = np.setdiff1d(np.asarray(flat_train.columns), column_filter)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#n_month = 15\n",
    "last_date = '2018-02-01'\n",
    "\n",
    "for i in range(5):\n",
    "    n_month = 15\n",
    "    lgb_model = lgb.LGBMRegressor(n_estimators = 200, random_state = 42+i, predict_leaf_index = True)\n",
    "    \n",
    "    submission_1 = my_submit(\n",
    "                            model = lgb_model, \n",
    "                            dataset = flat_train,\n",
    "                            right_dataset = full[['id','is_train','bulk_spalen_id','value','date1']],\n",
    "                            right_date = fixed_days[31], \n",
    "                            cv_dates = [30], \n",
    "                            last_date = last_date,\n",
    "                            n_month = n_month,\n",
    "                            study_columns = column_study, \n",
    "                            value_column = 'value_1', \n",
    "                            group_columns = 'bulk_spalen_id',\n",
    "                            random_state=442, \n",
    "                            importance_flag = True)\n",
    "\n",
    "    submission_2 = my_submit(\n",
    "                            model = lgb_model, \n",
    "                            dataset = flat_train,\n",
    "                            right_dataset = full[['id','is_train','bulk_spalen_id','value','date1']],\n",
    "                            right_date = fixed_days[32], \n",
    "                            cv_dates = [29],\n",
    "                            last_date = last_date,\n",
    "                            n_month = n_month,\n",
    "                            study_columns = column_study, \n",
    "                            value_column = 'value_2', \n",
    "                            group_columns = 'bulk_spalen_id',\n",
    "                            random_state=442, \n",
    "                            importance_flag = True)\n",
    "\n",
    "    submission_3 = my_submit(\n",
    "                            model = lgb_model, \n",
    "                            dataset = flat_train,\n",
    "                            right_dataset = full[['id','is_train','bulk_spalen_id','value','date1']],\n",
    "                            right_date = fixed_days[33],\n",
    "                            cv_dates = [28],\n",
    "                            last_date = last_date,\n",
    "                            n_month = n_month,\n",
    "                            study_columns = column_study, \n",
    "                            value_column = 'value_3', \n",
    "                            group_columns = 'bulk_spalen_id',\n",
    "                            random_state=442, \n",
    "                            importance_flag = True)\n",
    "\n",
    "\n",
    "    submission = pd.concat([submission_1,submission_2,submission_3]).fillna(0).sort_values('id')\n",
    "    \n",
    "    if i==0:\n",
    "        v = submission['value']\n",
    "    else: \n",
    "        v = v + submission['value']\n",
    "        \n",
    "submission['value'] = v/(i+1)        \n",
    "\n",
    "filename = f'results/afterparty/x_5_nmonth_15.csv'\n",
    "#submission.to_csv(filename, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Само обучение на квартирах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель на train.csv и test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_one_model_cv(model, dataset, study_columns, random_state=442, importance_flag = False):\n",
    "    \n",
    "    train_agg = dataset[dataset.is_train==1].copy()\n",
    "    test_agg = dataset[dataset.is_train==0].copy()\n",
    "    \n",
    "    ind = 0\n",
    "    _mse = np.array([],dtype = 'float')\n",
    "    #заполним нулями предикт теста\n",
    "    y_test_pred = np.zeros(test_agg.shape[0],dtype = 'float')\n",
    "\n",
    "    #основная кросс-валидация\n",
    "    for train_index, valid_index in KFold(n_splits=5, random_state=random_state, shuffle = True).split(train_agg):   \n",
    "\n",
    "        tmp_train  = train_agg.loc[train_index,:]   \n",
    "        tmp_valid  = train_agg.loc[valid_index,:]\n",
    "        tmp_test   = test_agg.copy()\n",
    "\n",
    "        #учиться будем только на study_columns не на всех переменных     \n",
    "        X_train = tmp_train.loc[:,study_columns]\n",
    "        X_valid = tmp_valid.loc[:,study_columns]\n",
    "        X_test  = tmp_test.loc[:,study_columns]\n",
    "\n",
    "        y_train = tmp_train['value']\n",
    "        y_valid = tmp_valid['value']\n",
    "        \n",
    "        #обучим модель\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "\n",
    "        \n",
    "        y_valid_pred = model.predict(X_valid)\n",
    "        y_test_pred = y_test_pred+model.predict(X_test)\n",
    "        \n",
    "        \n",
    "        y_valid_pred[y_valid_pred<0] = 0\n",
    "        \n",
    "        if ind ==0:\n",
    "            stacking_df = pd.DataFrame(dict({'bulk_id_int':tmp_valid.bulk_id_int,'predict':y_valid_pred, 'fact':y_valid}))\n",
    "        else:\n",
    "            tmp_stacking_df = pd.DataFrame(dict({'bulk_id_int':tmp_valid.bulk_id_int,'predict':y_valid_pred, 'fact':y_valid}))\n",
    "            stacking_df = stacking_df.append(tmp_stacking_df).sort_values('bulk_id_int')\n",
    "        \n",
    "        \n",
    "        _mse = np.append(_mse,mean_squared_error(y_valid,y_valid_pred))\n",
    "\n",
    "        ind = ind + 1\n",
    "\n",
    "        #break\n",
    "    \n",
    "    \n",
    "    importance = pd.DataFrame(dict({'feature':'none', 'delta_mse':0}), index = ['none'])\n",
    "    \n",
    "    mse_now = mean_squared_error(y_valid,y_valid_pred)\n",
    "    NUMBER_SHUFFLE = 5\n",
    "    if importance_flag:\n",
    "        for feature in study_columns:\n",
    "\n",
    "            tmp_mse = 0\n",
    "            for i in range(NUMBER_SHUFFLE):\n",
    "                _X_valid = X_valid.copy()\n",
    "                a = np.asarray(X_valid[feature].copy())\n",
    "                np.random.shuffle(a)\n",
    "                _X_valid[feature] = a\n",
    "                y_valid_pred = model.predict(_X_valid)\n",
    "                tmp_mse = tmp_mse+mean_squared_error(y_valid, y_valid_pred)/NUMBER_SHUFFLE\n",
    "            tmp_importance = pd.DataFrame(dict({'feature':feature, 'delta_mse':(tmp_mse-mse_now)}), index = [feature])    \n",
    "            importance = importance.append(tmp_importance) \n",
    "    \n",
    "    \n",
    "    #усредняем по фолдам предсказание теста\n",
    "    y_test_pred = y_test_pred/ind\n",
    "    \n",
    "    y_test_pred[y_test_pred<0] = 0\n",
    "    \n",
    "    submission = pd.DataFrame(dict({'id':test_agg.id,'value':y_test_pred}))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return submission, _mse, stacking_df, importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['price_by_square'] = full['price']/full['mean_sq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_filter = ['value','start_square','plan_s','plan_m','plan_l','vid_0','vid_1','vid_2',\n",
    "#                 'date1','bulk_id','is_train','id','date2']\n",
    "                 #,'calc_last_value', 'calc_start_square']\n",
    "#column_study = np.setdiff1d(np.asarray(full.columns), column_filter)\n",
    "\n",
    "column_study = np.array(['Cтавка по ипотеке', 'Date_int', 'bulk_id_int', 'mean_fl',\n",
    "       'mean_sq', 'month', 'month_cnt', 'price', 'price_by_square',\n",
    "       'spalen', 'Автомойка', 'Вентлияция', 'Видеонаблюдение',\n",
    "       'Вклады до 1 года', 'Вклады от 1 года до 3 лет',\n",
    "       'Вклады свыше 3 лет', 'Входные группы', 'Двор без машин',\n",
    "       'Детский сад', 'До Кремля', 'До Садового(км)', 'До ТТК(км)',\n",
    "       'До большой дороги на машине(км)', 'До метро пешком(км)',\n",
    "       'До парка пешком(км)', 'До парка(км)', 'До промки(км)',\n",
    "       'До удобной авторазвязки на машине(км)', 'Кладовые',\n",
    "       'Класс объекта', 'Количество помещений', 'Колясочные',\n",
    "       'Кондиционирование', 'Курс', 'Лифт', 'Машиномест',\n",
    "       'Огорожена территория', 'Площадь двора',\n",
    "       'Площадь зеленой зоны в радиусе 500 м',\n",
    "       'Площадь земельного участка', 'Площадь пром. зоны в радиусе 500 м',\n",
    "       'Подземная парковка', 'Поликлиника', 'Система мусоротведения',\n",
    "       'Спортивная площадка', 'Станций метро от кольца', 'ФОК', 'Школа'])\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators = 550, random_state = 42)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "      \n",
    "\n",
    "    submission_lgb, mse, stacking_df, imp_df = my_one_model_cv(lgb_model, full, column_study, random_state=442, importance_flag = True)\n",
    "\n",
    "    submission_lgb = submission_lgb.sort_values('id')\n",
    "    if i==0:\n",
    "        v = submission_lgb['value']\n",
    "    else: \n",
    "        v = v + submission_lgb['value']\n",
    "        \n",
    "submission_lgb['value'] = v/(i+1)   \n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "submission_lgb = submission_lgb.sort_values('id')\n",
    "filename = f'results/lgb_x_5.csv'\n",
    "#submission_lgb.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgb = submission_lgb\n",
    "best_flat = submission\n",
    "\n",
    "\n",
    "best = best_flat.merge(best_lgb, on = 'id')\n",
    "best.loc[best['value_x']==0, 'value_x'] = best.loc[best['value_x']==0, 'value_y']\n",
    "best['value'] = 0.7*best['value_x']+0.3*best['value_y']\n",
    "\n",
    "\n",
    "filename = f'results/afterparty/blend_auto_x5.csv'\n",
    "best[['id','value']].to_csv(filename, index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['balcon', 'bulk_spalen_id', 'cnt_stat_new_0', 'cnt_stat_new_1',\n",
       "       'cnt_stat_new_2', 'cnt_stat_new_3', 'cnt_stat_new_4',\n",
       "       'cnt_stat_new_5', 'cnt_stat_new_6', 'dt_settle_salestart',\n",
       "       'dt_to_salestart', 'dt_to_settle', 'floor', 'id_flatwork_int',\n",
       "       'last_stat_new', 'month_cnt', 'otdelka', 'plan0', 'plan_size',\n",
       "       'pricem2', 'section', 'spalen', 'square', 'stage_number',\n",
       "       'stat_new', 'status_days', 'vid', 'Автомойка', 'Вентлияция',\n",
       "       'Видеонаблюдение', 'Входные группы', 'Двор без машин',\n",
       "       'Детский сад', 'До Кремля', 'До Садового(км)', 'До ТТК(км)',\n",
       "       'До большой дороги на машине(км)', 'До метро пешком(км)',\n",
       "       'До парка пешком(км)', 'До парка(км)', 'До промки(км)',\n",
       "       'До удобной авторазвязки на машине(км)', 'Кладовые',\n",
       "       'Класс объекта', 'Количество помещений', 'Колясочные',\n",
       "       'Кондиционирование', 'Лифт', 'Машиномест', 'Огорожена территория',\n",
       "       'Площадь двора', 'Площадь зеленой зоны в радиусе 500 м',\n",
       "       'Площадь земельного участка', 'Площадь пром. зоны в радиусе 500 м',\n",
       "       'Подземная парковка', 'Поликлиника', 'Система мусоротведения',\n",
       "       'Спортивная площадка', 'Станций метро от кольца', 'ФОК', 'Школа'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date1\n",
       "2015-07-01     6130\n",
       "2015-08-01     8256\n",
       "2015-09-01     8971\n",
       "2015-10-01     9506\n",
       "2015-11-01    10183\n",
       "2015-12-01     9604\n",
       "2016-01-01     9408\n",
       "2016-02-01     9197\n",
       "2016-03-01    10107\n",
       "2016-04-01    12433\n",
       "2016-05-01    12541\n",
       "2016-06-01    12131\n",
       "2016-07-01    12087\n",
       "2016-08-01    11942\n",
       "2016-09-01    12117\n",
       "2016-10-01    12222\n",
       "2016-11-01    11469\n",
       "2016-12-01    38890\n",
       "2017-01-01    42313\n",
       "2017-02-01    19884\n",
       "2017-03-01    21677\n",
       "2017-04-01    23206\n",
       "2017-05-01    26751\n",
       "2017-06-01    26912\n",
       "2017-07-01    25459\n",
       "2017-08-01    24996\n",
       "2017-09-01    27433\n",
       "2017-10-01    28498\n",
       "2017-11-01    26913\n",
       "2017-12-01    27247\n",
       "2018-01-01    25887\n",
       "2018-02-01    25863\n",
       "2018-03-01    25863\n",
       "2018-04-01    25863\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_train.groupby('date1').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_1 = pd.read_csv('results/send/blend_auto.csv', encoding='cp1251')\n",
    "#best_2 = pd.read_csv('results/send/blend_auto_x5.csv', encoding='cp1251')\n",
    "\n",
    "#best = best_1.merge(best_2, on = 'id')\n",
    "#best['value'] = 0.5*best['value_x']+0.5*best['value_y']\n",
    "\n",
    "#filename = f'results/blend_blend_x5.csv'\n",
    "#best[['id','value']].to_csv(filename, index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['balcon', 'bulk_spalen_id', 'cnt_stat_new_0', 'cnt_stat_new_1',\n",
       "       'cnt_stat_new_2', 'cnt_stat_new_3', 'cnt_stat_new_4',\n",
       "       'cnt_stat_new_5', 'cnt_stat_new_6', 'dt_settle_salestart',\n",
       "       'dt_to_salestart', 'dt_to_settle', 'floor', 'id_flatwork_int',\n",
       "       'last_stat_new', 'month_cnt', 'otdelka', 'plan0', 'plan_size',\n",
       "       'pricem2', 'section', 'spalen', 'square', 'stage_number',\n",
       "       'stat_new', 'status_days', 'vid', 'Автомойка', 'Вентлияция',\n",
       "       'Видеонаблюдение', 'Входные группы', 'Двор без машин',\n",
       "       'Детский сад', 'До Кремля', 'До Садового(км)', 'До ТТК(км)',\n",
       "       'До большой дороги на машине(км)', 'До метро пешком(км)',\n",
       "       'До парка пешком(км)', 'До парка(км)', 'До промки(км)',\n",
       "       'До удобной авторазвязки на машине(км)', 'Кладовые',\n",
       "       'Класс объекта', 'Количество помещений', 'Колясочные',\n",
       "       'Кондиционирование', 'Лифт', 'Машиномест', 'Огорожена территория',\n",
       "       'Площадь двора', 'Площадь зеленой зоны в радиусе 500 м',\n",
       "       'Площадь земельного участка', 'Площадь пром. зоны в радиусе 500 м',\n",
       "       'Подземная парковка', 'Поликлиника', 'Система мусоротведения',\n",
       "       'Спортивная площадка', 'Станций метро от кольца', 'ФОК', 'Школа'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_filter = ['id_sec','id_gk','id_flatwork','date_settle', \n",
    "                 'date_salestart','sale','bulk_id',\n",
    "                 'date1','realized_1', 'realized_2', 'realized_3',\n",
    "                 'value_1','value_2', 'value_3']\n",
    "\n",
    "                \n",
    "column_study = np.setdiff1d(np.asarray(flat_train.columns), column_filter)\n",
    "column_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_lgb = submission_lgb\n",
    "#best_flat = submission\n",
    "\n",
    "\n",
    "#best = best_flat.merge(best_lgb, on = 'id')\n",
    "#best.loc[best['value_x']==0, 'value_x'] = best.loc[best['value_x']==0, 'value_y']\n",
    "#best['value'] = 0.7*best['value_x']+0.3*best['value_y']\n",
    "\n",
    "#idea4 = pd.read_csv('results/send/idea4_mse_15.5509_0.0000.csv', encoding='cp1251')\n",
    "\n",
    "#best = best[['id','value']].merge(idea4, on = 'id')\n",
    "#best['value'] = 0.85*best['value_x']+0.15*best['value_y']\n",
    "\n",
    "\n",
    "#filename = f'results/blend_auto_x5_idea4_085.csv'\n",
    "#best[['id','value']].to_csv(filename, index = False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
